{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Warning Help us to remove Non relevant Warning pop up During the Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Packages For Preprocessing the Textual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import utils, corpora, matutils, models \n",
    "from gensim.test.utils import common_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing  User defined Modules as well as user defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting MongoDB Data Connection to Fetch Records and Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmean_clus',\n",
       " 'Cls_Data_500',\n",
       " 'Beast_kmean_Data',\n",
       " 'Sample20',\n",
       " 'Dump_1',\n",
       " 'LDA_Database',\n",
       " 'Cls_Data',\n",
       " 'aff_clus',\n",
       " 'Fzy_Kmean']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient() # class of mongoDb\n",
    "client = MongoClient('localhost', 27017) # connection port\n",
    "\n",
    "mydb = client['New_Data_Email']  # Conneting DataBase using connection port\n",
    "mydb.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'New_Data_Email'), 'Sample20')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = mydb[\"Sample20\"]\n",
    "collection_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the Path of Directory where the Result of Preprocessing Get saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\1_JD_IPYTHON\\Sep_Kmean_Lda_Genism_Output_Data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "Folder_Name = str(\"Sep_Kmean_Lda_Genism_Output_Data\")\n",
    "Base_path = str(\"D:\\\\1_JD_IPYTHON\\\\\")\n",
    "def Change_dir_path(Base_path,Folder_Name):\n",
    "    Change_dir = os.chdir(Base_path+Folder_Name)\n",
    "Change_dir_path(Base_path,Folder_Name)\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Records from Data Base Into Pandas Dat Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 7 columns):\n",
      "Body_       20000 non-null object\n",
      "Date_       20000 non-null object\n",
      "Doc_N       20000 non-null int64\n",
      "From_       20000 non-null object\n",
      "Subject_    20000 non-null object\n",
      "TO_         19156 non-null object\n",
      "_id         20000 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "Data_email = pd.DataFrame(list(collection_name.find()))\n",
    "Data_email.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating New Pandas Data Frame for Safer Side Copy Records In new One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 7 columns):\n",
      "Body_       20000 non-null object\n",
      "Date_       20000 non-null object\n",
      "Doc_N       20000 non-null int64\n",
      "From_       20000 non-null object\n",
      "Subject_    20000 non-null object\n",
      "TO_         19156 non-null object\n",
      "_id         20000 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "New_Email_Df = Data_email\n",
    "New_Email_Df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Body_', 'Date_', 'Doc_N', 'From_', 'Subject_', 'TO_', '_id'], dtype='object')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Email_Df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joblib for Parallel Exceution of Data\n",
    "## Importing Preprocee file which Clean the Non Relevant words\n",
    "#### URL links, To ,From, Chain Email Sender and Recivers Names ,com etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cleaning_email_body_updated_JD\n",
    "from Cleaning_email_body_updated_JD import Cleaning_email_pandas\n",
    "from joblib import Parallel , delayed\n",
    "New_Email_Df = New_Email_Df[0:500]\n",
    "Body_text = Parallel(n_jobs=3)(delayed(Cleaning_email_pandas)(x)for x in New_Email_Df[\"Body_\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Body_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, list)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Cleaning_email_body_updated_JD import  Gensim_preprocess\n",
    "Gensim_Result = Parallel(n_jobs=2,backend='threading')(delayed(Gensim_preprocess)(text) for text in Body_text)\n",
    "len(Gensim_Result),type(Gensim_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below Code is removing or filter words which suggested by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cleaning_email_body_updated_JD import  Next_Level_Word_Clean\n",
    "NEW_Clean_Corpus = Parallel(n_jobs=2,backend='threading')(delayed(Next_Level_Word_Clean)(text) for text in Gensim_Result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkdadhich\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Clean_text_email = [\" \".join(x)  for x in NEW_Clean_Corpus] # Rejoing the words\n",
    "New_Email_Df[\"Doc_Number\"]   = [ int(x+1) for x in range(len(New_Email_Df))] # Giving Document Seq.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NEW_Clean_Corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dictionary of Corpus how many time words appears in entire text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(4163 unique tokens: ['contractors', 'mckinsey', 'removed', 'end', 'catch']...)\n"
     ]
    }
   ],
   "source": [
    "Change_dir_path(Base_path,Folder_Name)\n",
    "def Dic_TFIDF_Corpus(texts):\n",
    "    #File_path_detail_log.Gensim_Results()\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    dictionary.filter_extremes(no_below=2)\n",
    "    dictionary.compactify()\n",
    "    dictionary.save('dict_1.dict')\n",
    "    print (dictionary)\n",
    "    # Creating Verctors\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    return corpus\n",
    "\n",
    "Corpus_email =    Dic_TFIDF_Corpus(NEW_Clean_Corpus) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the TF ~ IDF (term frequency and Inverse frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x209480024e0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_email = models.TfidfModel(Corpus_email)\n",
    "Corpus_tfidf_email = tfidf_email[Corpus_email]\n",
    "Corpus_tfidf_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing LDA Topic Modeling With User Pass number of Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Factor are number of Topic, number of passes and alpa & beta however we used default right now (under research)\n",
    "Dictionary as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Change_dir_path(Base_path,Folder_Name)\n",
    "dictionary_email = gensim.corpora.Dictionary.load(\"dict_1.dict\")\n",
    "Number_of_Topics = 10\n",
    "Lda_model_user = models.LdaModel(Corpus_tfidf_email, id2word=dictionary_email, \n",
    "                      num_topics=Number_of_Topics,minimum_probability=0,\n",
    "                      random_state=2,passes = 10,\n",
    "                      per_word_topics=False,\n",
    "                      )\n",
    "Lda_model_user.save(\"LDA_Model.save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Index for Document Similarity (Using Cosine In backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "index_email = similarities.MatrixSimilarity(Lda_model_user[Corpus_tfidf_email])\n",
    "len(index_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Taking Out the One Dimension array from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_d_index = np.asanyarray(index_email)\n",
    "One_d_index_Fetch = One_d_index[0]\n",
    "One_d_index_Fetch = One_d_index_Fetch.reshape((-1,1))\n",
    "One_d_index_Fetch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the NLTK Cosine Clustering Using Index as Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette_score  :\t 59.83\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "Random_Value = random.randint(1,1)\n",
    "import nltk\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "NUM_CLUSTERS = Number_of_Topics\n",
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, \n",
    "                             distance=nltk.cluster.util.cosine_distance, \n",
    "                             repeats=25)\n",
    "\n",
    "NLTK_clusters = kclusterer.cluster(index_email, assign_clusters=True)\n",
    "from sklearn import metrics\n",
    "silhouette_score = metrics.silhouette_score(index_email, NLTK_clusters, metric='cosine')\n",
    "print (\"Silhouette_score  :\\t\",round(silhouette_score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Kmean Clustering On the One D array which created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette_score  :\t 59.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans_email = KMeans(n_clusters=Number_of_Topics, random_state=0,max_iter=10).fit(One_d_index_Fetch)\n",
    "kmeans_email.labels_\n",
    "from sklearn import metrics\n",
    "silhouette_score = metrics.silhouette_score(One_d_index_Fetch, kmeans_email.labels_, metric='euclidean')\n",
    "print (\"Silhouette_score  :\\t\",round(silhouette_score*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Using Topic Word Probability wrt to document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lda      = Lda_model_user[Corpus_tfidf_email]\n",
    "lda_corpus_porb = [max(prob,key=lambda y:y[1])for prob in corpus_lda ]\n",
    "lists_label     = [ x[0] for i, x in enumerate(lda_corpus_porb) ]\n",
    "Max_prob        = [ round(x[1]*100,4) for i, x in enumerate(lda_corpus_porb) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette_score  :\t 82.32\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "silhouette_score = metrics.silhouette_score(lda_corpus_porb, lists_label, metric='euclidean')\n",
    "print (\"Silhouette_score  :\\t\",round(silhouette_score*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the Result over the Pandas Using Topic Word Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body_</th>\n",
       "      <th>Date_</th>\n",
       "      <th>Doc_N</th>\n",
       "      <th>From_</th>\n",
       "      <th>Subject_</th>\n",
       "      <th>TO_</th>\n",
       "      <th>_id</th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>SIM_Matirx</th>\n",
       "      <th>TF_IDF_LDA</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Prob_Label</th>\n",
       "      <th>Max_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---------------------- forwarded by phillip m ...</td>\n",
       "      <td>Wed, 7 Jun 2000 11:43:00 -0700 (PDT)</td>\n",
       "      <td>294217</td>\n",
       "      <td>phillip.love@enron.com</td>\n",
       "      <td>Transport</td>\n",
       "      <td>delma.salazar@enron.com</td>\n",
       "      <td>5b4cbc56f63a094ed82a0e45</td>\n",
       "      <td>1</td>\n",
       "      <td>(1.0000001, 0.069377705, 0.09498313, 0.0854087...</td>\n",
       "      <td>[(0, 0.032012727), (1, 0.7118682), (2, 0.03201...</td>\n",
       "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]</td>\n",
       "      <td>1</td>\n",
       "      <td>71.1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as per our discussion, can you please send a d...</td>\n",
       "      <td>Fri, 1 Jun 2001 04:39:00 -0700 (PDT)</td>\n",
       "      <td>193674</td>\n",
       "      <td>justin.rostant@enron.com</td>\n",
       "      <td>NDA request</td>\n",
       "      <td>tana.jones@enron.com</td>\n",
       "      <td>5b4cbc55f63a094ed8288586</td>\n",
       "      <td>2</td>\n",
       "      <td>(0.069377705, 0.99999994, 0.053943243, 0.05330...</td>\n",
       "      <td>[(0, 0.015857045), (1, 0.01585025), (2, 0.8573...</td>\n",
       "      <td>[(5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>85.7317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello,\\n\\n an internal meeting to discuss tran...</td>\n",
       "      <td>Tue, 31 Oct 2000 04:39:00 -0800 (PST)</td>\n",
       "      <td>469031</td>\n",
       "      <td>laura.wente@enron.com</td>\n",
       "      <td>Transmission Meetings</td>\n",
       "      <td>don.hammond@enron.com, stan.gray@enron.com, an...</td>\n",
       "      <td>5b4cbc57f63a094ed82cb923</td>\n",
       "      <td>3</td>\n",
       "      <td>(0.09498313, 0.053943243, 0.99999994, 0.072800...</td>\n",
       "      <td>[(0, 0.015469199), (1, 0.015470081), (2, 0.015...</td>\n",
       "      <td>[(11, 1), (41, 2), (42, 1), (43, 1), (44, 1), ...</td>\n",
       "      <td>9</td>\n",
       "      <td>47.5736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>----- forwarded by cindy derecskey/corp/enron ...</td>\n",
       "      <td>Tue, 8 May 2001 01:16:00 -0700 (PDT)</td>\n",
       "      <td>435164</td>\n",
       "      <td>cindy.derecskey@enron.com</td>\n",
       "      <td>ADDITIONAL DOCUMENT - WSJ Documents for Ken Lay</td>\n",
       "      <td>richard.shapiro@enron.com, steven.kean@enron.c...</td>\n",
       "      <td>5b4cbc57f63a094ed82c34d8</td>\n",
       "      <td>4</td>\n",
       "      <td>(0.085408755, 0.05330132, 0.072800055, 0.99999...</td>\n",
       "      <td>[(0, 0.023971025), (1, 0.023974534), (2, 0.023...</td>\n",
       "      <td>[(0, 1), (87, 3), (88, 2), (89, 1), (90, 1), (...</td>\n",
       "      <td>5</td>\n",
       "      <td>78.4217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on saturday, june 9, tropical storm allison le...</td>\n",
       "      <td>Mon, 11 Jun 2001 08:57:00 -0700 (PDT)</td>\n",
       "      <td>384278</td>\n",
       "      <td>office.chairman@enron.com</td>\n",
       "      <td>Houston Flood Relief Effort</td>\n",
       "      <td>all.worldwide@enron.com</td>\n",
       "      <td>5b4cbc57f63a094ed82b6e12</td>\n",
       "      <td>5</td>\n",
       "      <td>(0.06896205, 0.2146638, 0.646569, 0.051177546,...</td>\n",
       "      <td>[(0, 0.009966641), (1, 0.009963509), (2, 0.152...</td>\n",
       "      <td>[(34, 3), (71, 1), (79, 1), (99, 1), (100, 1),...</td>\n",
       "      <td>8</td>\n",
       "      <td>76.7558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Body_  \\\n",
       "0  ---------------------- forwarded by phillip m ...   \n",
       "1  as per our discussion, can you please send a d...   \n",
       "2  hello,\\n\\n an internal meeting to discuss tran...   \n",
       "3  ----- forwarded by cindy derecskey/corp/enron ...   \n",
       "4  on saturday, june 9, tropical storm allison le...   \n",
       "\n",
       "                                   Date_   Doc_N                      From_  \\\n",
       "0   Wed, 7 Jun 2000 11:43:00 -0700 (PDT)  294217     phillip.love@enron.com   \n",
       "1   Fri, 1 Jun 2001 04:39:00 -0700 (PDT)  193674   justin.rostant@enron.com   \n",
       "2  Tue, 31 Oct 2000 04:39:00 -0800 (PST)  469031      laura.wente@enron.com   \n",
       "3   Tue, 8 May 2001 01:16:00 -0700 (PDT)  435164  cindy.derecskey@enron.com   \n",
       "4  Mon, 11 Jun 2001 08:57:00 -0700 (PDT)  384278  office.chairman@enron.com   \n",
       "\n",
       "                                          Subject_  \\\n",
       "0                                        Transport   \n",
       "1                                      NDA request   \n",
       "2                            Transmission Meetings   \n",
       "3  ADDITIONAL DOCUMENT - WSJ Documents for Ken Lay   \n",
       "4                      Houston Flood Relief Effort   \n",
       "\n",
       "                                                 TO_  \\\n",
       "0                            delma.salazar@enron.com   \n",
       "1                               tana.jones@enron.com   \n",
       "2  don.hammond@enron.com, stan.gray@enron.com, an...   \n",
       "3  richard.shapiro@enron.com, steven.kean@enron.c...   \n",
       "4                            all.worldwide@enron.com   \n",
       "\n",
       "                        _id  Doc_Number  \\\n",
       "0  5b4cbc56f63a094ed82a0e45           1   \n",
       "1  5b4cbc55f63a094ed8288586           2   \n",
       "2  5b4cbc57f63a094ed82cb923           3   \n",
       "3  5b4cbc57f63a094ed82c34d8           4   \n",
       "4  5b4cbc57f63a094ed82b6e12           5   \n",
       "\n",
       "                                          SIM_Matirx  \\\n",
       "0  (1.0000001, 0.069377705, 0.09498313, 0.0854087...   \n",
       "1  (0.069377705, 0.99999994, 0.053943243, 0.05330...   \n",
       "2  (0.09498313, 0.053943243, 0.99999994, 0.072800...   \n",
       "3  (0.085408755, 0.05330132, 0.072800055, 0.99999...   \n",
       "4  (0.06896205, 0.2146638, 0.646569, 0.051177546,...   \n",
       "\n",
       "                                          TF_IDF_LDA  \\\n",
       "0  [(0, 0.032012727), (1, 0.7118682), (2, 0.03201...   \n",
       "1  [(0, 0.015857045), (1, 0.01585025), (2, 0.8573...   \n",
       "2  [(0, 0.015469199), (1, 0.015470081), (2, 0.015...   \n",
       "3  [(0, 0.023971025), (1, 0.023974534), (2, 0.023...   \n",
       "4  [(0, 0.009966641), (1, 0.009963509), (2, 0.152...   \n",
       "\n",
       "                                              Corpus  Prob_Label  Max_Prob  \n",
       "0           [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]           1   71.1868  \n",
       "1  [(5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, ...           2   85.7317  \n",
       "2  [(11, 1), (41, 2), (42, 1), (43, 1), (44, 1), ...           9   47.5736  \n",
       "3  [(0, 1), (87, 3), (88, 2), (89, 1), (90, 1), (...           5   78.4217  \n",
       "4  [(34, 3), (71, 1), (79, 1), (99, 1), (100, 1),...           8   76.7558  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Data_frame = New_Email_Df.copy()\n",
    "\n",
    "Data_frame[\"SIM_Matirx\"]  =  index_email\n",
    "Data_frame[\"TF_IDF_LDA\"]  =  [ x for x in corpus_lda]\n",
    "Data_frame[\"Corpus\"]      =  [ x for x in Corpus_email]\n",
    "Data_frame[\"Prob_Label\"]  =  lists_label\n",
    "Data_frame[\"Max_Prob\"]    =  Max_prob\n",
    "\n",
    "Data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Body_', 'Date_', 'Doc_N', 'From_', 'Subject_', 'TO_', '_id',\n",
       "       'Doc_Number', 'SIM_Matirx', 'TF_IDF_LDA', 'Corpus', 'Prob_Label',\n",
       "       'Max_Prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_frame.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shorting the Data Frame for filter out the Next level Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_frame['Rank_Prob'] = Data_frame.groupby('Prob_Label')['Max_Prob'].rank(ascending=False)\n",
    "Data_frame.sort_values(by=['Prob_Label',\"Rank_Prob\"], ascending=[True,True],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calulating the Cosine Distance (Vector's of Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine,euclidean\n",
    "\n",
    "def Cos_SIM_Funct(X,Y):  \n",
    "    #X = [x[1] for x in X]\n",
    "    #Y = [x[1] for x in Y]\n",
    "    return round((1 - cosine(X,Y))*100,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine_mean_Sim(Cls_value):\n",
    "    Temp_df = Data_frame.loc[Data_frame.Prob_Label == int(Cls_value)]\n",
    "    Select_RanK_1 = Temp_df[\"SIM_Matirx\"].values[0]\n",
    "   # Select_RanK_1 = Temp_df[\"TF_IDF_LDA\"].values[0]\n",
    "    Value_cos_dis = []\n",
    "    print (\"~~@~~\"*10)\n",
    "    for x in Temp_df.SIM_Matirx:\n",
    "        Value_cos_dis.append(Cos_SIM_Funct(Select_RanK_1,x))\n",
    "         \n",
    "    Temp_df[\"Cos_Simlarity\"]  = Value_cos_dis\n",
    "    print (Value_cos_dis)\n",
    "    return Temp_df\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the Records Into Pandas Data Frame and also caluating the Distance cosine wrt of Hight Prob. of Document in that cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 100.0, 100.0, 99.9975, 99.9713, 99.957, 99.9423, 99.9118, 99.9013, 99.8749, 97.5623, 99.7218, 98.9785, 92.6798, 98.5986, 92.6578, 85.125, 84.1873, 97.6887, 97.6763, 83.4854, 81.4253, 74.1386, 78.833, 75.5063, 77.9097, 82.8635, 71.5847, 65.8181, 48.7248, 48.7248, 48.7248, 48.7248, 48.7248]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 99.9663, 99.9663, 99.9663, 99.9663, 99.9663, 99.9663, 99.9663, 99.9614, 99.9477, 99.9322, 99.9264, 99.9156, 99.8714, 99.8695, 99.8659, 99.8636, 99.8222, 99.7934, 99.7184, 97.6267, 96.9065, 99.5529, 99.5357, 99.4848, 99.3992, 99.2917, 92.2781, 99.0896, 95.1922, 93.921, 98.2397, 92.0996, 89.2603, 98.0553, 85.9779, 89.8663, 84.2521, 84.775, 79.5128, 96.3117, 79.2054, 71.9502, 69.6009, 68.0402, 82.2691, 73.0229, 65.2174, 61.8918]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkdadhich\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 99.9996, 99.9986, 99.9975, 99.9971, 99.9971, 99.9966, 99.9955, 99.9879, 99.9858, 99.982, 99.9674, 99.9656, 99.965, 99.9648, 99.9626, 99.5301, 99.9437, 99.9368, 99.9364, 99.9315, 99.9289, 99.9273, 99.9252, 99.9105, 99.9001, 99.8808, 99.7913, 99.3287, 97.9373, 99.6593, 96.5867, 95.3574, 94.5824, 94.5808, 96.1105, 99.1447, 98.4613, 91.0109, 97.9024, 88.0898, 89.7803, 87.4399, 85.9798, 84.6646, 86.2439, 83.3053, 83.5946, 83.3008, 97.1171, 80.0081, 85.482, 87.2705, 77.4505, 80.1391, 90.6443, 82.9652, 79.8687, 77.0051, 76.0151, 66.5391, 70.0937]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 99.9916, 99.9914, 99.989, 99.8791, 96.7454, 99.7618, 99.5369, 99.4806, 99.4176, 99.2009, 90.8573, 98.8754, 98.8754, 83.715, 97.6291, 83.7441, 95.7412, 95.7411, 84.7142, 73.6146, 83.4502, 75.2837, 71.6947, 71.24, 74.3033, 71.5879, 69.8973, 73.5218, 73.0976, 60.8623, 57.3641]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 99.9859, 99.9391, 99.9371, 99.902, 99.7741, 99.7127, 99.6835, 99.5957, 99.5489, 99.3961, 99.3872, 99.1542, 94.3631, 92.4048, 89.3393, 91.0133, 97.6951, 83.701, 88.2916, 97.0944, 91.4259, 82.8002, 75.2138, 74.625, 69.8398, 76.8038, 77.1468, 64.5912, 60.9723]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 99.9939, 99.9864, 99.9845, 99.9742, 99.9463, 99.9427, 99.9331, 99.9032, 99.8737, 99.8704, 99.8501, 99.8329, 99.8279, 99.809, 99.7636, 99.5423, 99.4651, 99.4496, 99.3474, 99.2011, 99.1628, 93.4214, 98.9081, 90.8928, 98.5465, 88.8081, 98.266, 87.8358, 87.2384, 87.3661, 86.6876, 90.504, 85.2439, 82.99, 81.8604, 84.4352, 86.4134, 96.3539, 86.9304, 79.1774, 76.4882, 81.9492, 77.0125, 73.4983, 71.3269, 68.8398, 75.0981, 69.3139, 71.3444, 67.1736, 65.4292]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 99.9731, 99.9705, 99.9448, 99.9207, 99.585, 95.2606, 99.0983, 92.6463, 90.0364, 93.3811, 98.5261, 89.9644, 85.789, 79.851, 80.9068, 76.2397, 94.2977, 77.711, 70.165, 75.9498, 76.1339, 67.947, 68.7449, 65.6243, 68.1557, 69.8549]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 100.0, 99.9994, 99.9879, 99.9853, 99.9493, 99.9327, 99.9164, 99.8881, 99.8086, 99.7447, 99.7447, 97.7818, 99.7198, 99.7159, 95.9082, 99.5564, 99.4984, 95.0403, 93.0973, 91.6008, 92.9634, 90.5392, 89.0657, 90.0801, 91.9811, 87.466, 86.9063, 87.0397, 86.2414, 84.862, 80.4302, 96.2497, 76.7224, 88.8829, 76.9196, 74.6476, 79.8907, 79.9872, 72.7587, 76.7881, 75.835, 72.2743, 76.6151, 76.9747, 68.8145, 67.7261, 65.3808]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 99.9998, 99.9997, 99.9996, 99.9994, 99.9994, 99.9991, 99.9988, 99.9986, 99.997, 99.9963, 99.9962, 99.995, 99.9933, 99.9926, 99.9924, 99.9907, 99.9904, 99.9897, 99.9888, 99.9886, 99.9884, 99.9883, 99.9877, 99.9851, 99.9836, 99.982, 99.9814, 99.9801, 99.9787, 99.9779, 99.9766, 99.9765, 99.9748, 99.9745, 99.9692, 99.9671, 99.9657, 99.964, 99.9634, 99.961, 99.9542, 99.9511, 99.6913, 99.9344, 99.9327, 99.9233, 99.9222, 99.9214, 99.9212, 99.9205, 99.316, 99.2971, 99.6771, 99.9052, 99.8465, 99.8459, 99.3007, 98.4752, 99.668, 99.3482, 98.9027, 99.5282, 98.2142, 99.6666, 99.2081, 97.9958, 99.5177, 98.6712, 98.5294, 98.66, 98.5914, 98.0007, 95.8891, 98.137, 96.92, 94.0651, 99.0894, 99.0893, 99.0891, 95.5763, 95.8639, 96.8928, 96.3356, 93.3665, 95.6945, 93.6179, 97.1048, 95.5271, 93.6562, 95.299, 91.5282, 92.1445, 94.7019, 95.2835, 95.6912, 96.1287, 94.9635, 95.5428, 94.6162, 91.5508, 90.4001, 95.3507, 94.5125, 91.4252, 92.4259, 91.1741, 93.8562, 93.5474, 91.3806, 92.059, 89.4721, 88.3606, 91.6273, 88.2361, 88.1461, 85.8202, 87.6407, 86.7229, 88.6421]\n",
      "~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~~~@~~\n",
      "[100.0, 100.0, 99.9904, 99.9478, 99.9419, 99.9155, 99.9132, 99.9058, 99.899, 99.8822, 99.8635, 99.8315, 97.6153, 99.7494, 97.6325, 99.6483, 97.1639, 99.5418, 94.9135, 95.38, 99.3795, 99.3652, 93.69, 95.4637, 91.037, 88.9728, 91.7866, 88.9778, 98.3143, 98.2544, 87.9781, 87.7029, 86.6586, 97.8617, 88.0038, 85.2652, 83.4918, 83.7248, 85.0666, 87.157, 95.8651, 73.8804, 76.733, 74.36, 71.8983, 77.6984]\n"
     ]
    }
   ],
   "source": [
    "blank_df = pd.DataFrame(columns=Data_frame.columns) \n",
    "for cls_ in range(Number_of_Topics):\n",
    "    blank_df = pd.concat([blank_df,Cosine_mean_Sim(Cls_value=cls_)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body_</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Cos_Simlarity</th>\n",
       "      <th>Date_</th>\n",
       "      <th>Doc_N</th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>From_</th>\n",
       "      <th>Max_Prob</th>\n",
       "      <th>Prob_Label</th>\n",
       "      <th>Rank_Prob</th>\n",
       "      <th>SIM_Matirx</th>\n",
       "      <th>Subject_</th>\n",
       "      <th>TF_IDF_LDA</th>\n",
       "      <th>TO_</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dave,\\n\\nwe had a meeting today with mark frev...</td>\n",
       "      <td>[(12, 1), (53, 1), (64, 2), (208, 1), (219, 1)...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Mon, 17 Jul 2000 11:25:00 -0700 (PDT)</td>\n",
       "      <td>263373</td>\n",
       "      <td>441</td>\n",
       "      <td>kimberly.hillis@enron.com</td>\n",
       "      <td>84.2785</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0723559, 0.04214374, 0.057439364, 0.0560173...</td>\n",
       "      <td>Alberta PPA</td>\n",
       "      <td>[(0, 0.8427851), (1, 0.017466994), (2, 0.01746...</td>\n",
       "      <td>david.delainey@enron.com</td>\n",
       "      <td>5b4cbc56f63a094ed82995c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>i will be out on th &amp; fri because my wife is h...</td>\n",
       "      <td>[(42, 1), (113, 1), (162, 1), (169, 1), (177, ...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Wed, 24 Jan 2001 08:32:00 -0800 (PST)</td>\n",
       "      <td>120775</td>\n",
       "      <td>277</td>\n",
       "      <td>rob.gay@enron.com</td>\n",
       "      <td>84.2707</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.07236882, 0.04215669, 0.05746351, 0.0560301...</td>\n",
       "      <td>Wife's surgery and Bersani</td>\n",
       "      <td>[(0, 0.8427131), (1, 0.017473105), (2, 0.01747...</td>\n",
       "      <td>peter.weidler@enron.com</td>\n",
       "      <td>5b4cbc54f63a094ed82768c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>can you kill this deal or zero out the volumes...</td>\n",
       "      <td>[(38, 3), (84, 1), (156, 2), (192, 1), (287, 2...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Wed, 25 Apr 2001 08:13:00 -0700 (PDT)</td>\n",
       "      <td>468500</td>\n",
       "      <td>419</td>\n",
       "      <td>rhonda.denton@enron.com</td>\n",
       "      <td>84.2613</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.07239429, 0.0421756, 0.05748879, 0.05604868...</td>\n",
       "      <td>Re: 581368</td>\n",
       "      <td>[(0, 0.84261274), (1, 0.017488237), (2, 0.0174...</td>\n",
       "      <td>kate.symes@enron.com</td>\n",
       "      <td>5b4cbc57f63a094ed82cb710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>this deal was not put in right.  the primary t...</td>\n",
       "      <td>[(0, 1), (38, 1), (76, 1), (79, 1), (82, 1), (...</td>\n",
       "      <td>99.9975</td>\n",
       "      <td>Wed, 13 Sep 2000 06:37:00 -0700 (PDT)</td>\n",
       "      <td>108318</td>\n",
       "      <td>320</td>\n",
       "      <td>julie.meyers@enron.com</td>\n",
       "      <td>83.4331</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(0.074123114, 0.043649085, 0.0595716, 0.057638...</td>\n",
       "      <td>Re: Meter 6879 - Sept. 00</td>\n",
       "      <td>[(0, 0.8343554), (1, 0.01839862), (2, 0.018399...</td>\n",
       "      <td>daren.farmer@enron.com</td>\n",
       "      <td>5b4cbc54f63a094ed827381a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>again mark i am flattered that you include me ...</td>\n",
       "      <td>[(160, 1), (169, 1), (256, 2), (288, 3), (641,...</td>\n",
       "      <td>99.9713</td>\n",
       "      <td>Fri, 28 Apr 2000 03:45:00 -0700 (PDT)</td>\n",
       "      <td>410864</td>\n",
       "      <td>168</td>\n",
       "      <td>susan.scott@enron.com</td>\n",
       "      <td>81.4350</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(0.07847097, 0.047362793, 0.06464015, 0.061656...</td>\n",
       "      <td>Re: 5 day loss limit violation (4/20 -4/27/2000)</td>\n",
       "      <td>[(0, 0.8143492), (1, 0.020624613), (2, 0.02062...</td>\n",
       "      <td>mark.fondren@enron.com</td>\n",
       "      <td>5b4cbc57f63a094ed82bd5ec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Body_  \\\n",
       "440  dave,\\n\\nwe had a meeting today with mark frev...   \n",
       "276  i will be out on th & fri because my wife is h...   \n",
       "418  can you kill this deal or zero out the volumes...   \n",
       "319  this deal was not put in right.  the primary t...   \n",
       "167  again mark i am flattered that you include me ...   \n",
       "\n",
       "                                                Corpus  Cos_Simlarity  \\\n",
       "440  [(12, 1), (53, 1), (64, 2), (208, 1), (219, 1)...       100.0000   \n",
       "276  [(42, 1), (113, 1), (162, 1), (169, 1), (177, ...       100.0000   \n",
       "418  [(38, 3), (84, 1), (156, 2), (192, 1), (287, 2...       100.0000   \n",
       "319  [(0, 1), (38, 1), (76, 1), (79, 1), (82, 1), (...        99.9975   \n",
       "167  [(160, 1), (169, 1), (256, 2), (288, 3), (641,...        99.9713   \n",
       "\n",
       "                                     Date_   Doc_N Doc_Number  \\\n",
       "440  Mon, 17 Jul 2000 11:25:00 -0700 (PDT)  263373        441   \n",
       "276  Wed, 24 Jan 2001 08:32:00 -0800 (PST)  120775        277   \n",
       "418  Wed, 25 Apr 2001 08:13:00 -0700 (PDT)  468500        419   \n",
       "319  Wed, 13 Sep 2000 06:37:00 -0700 (PDT)  108318        320   \n",
       "167  Fri, 28 Apr 2000 03:45:00 -0700 (PDT)  410864        168   \n",
       "\n",
       "                         From_  Max_Prob Prob_Label  Rank_Prob  \\\n",
       "440  kimberly.hillis@enron.com   84.2785          0        1.0   \n",
       "276          rob.gay@enron.com   84.2707          0        2.0   \n",
       "418    rhonda.denton@enron.com   84.2613          0        3.0   \n",
       "319     julie.meyers@enron.com   83.4331          0        4.0   \n",
       "167      susan.scott@enron.com   81.4350          0        5.0   \n",
       "\n",
       "                                            SIM_Matirx  \\\n",
       "440  (0.0723559, 0.04214374, 0.057439364, 0.0560173...   \n",
       "276  (0.07236882, 0.04215669, 0.05746351, 0.0560301...   \n",
       "418  (0.07239429, 0.0421756, 0.05748879, 0.05604868...   \n",
       "319  (0.074123114, 0.043649085, 0.0595716, 0.057638...   \n",
       "167  (0.07847097, 0.047362793, 0.06464015, 0.061656...   \n",
       "\n",
       "                                             Subject_  \\\n",
       "440                                       Alberta PPA   \n",
       "276                        Wife's surgery and Bersani   \n",
       "418                                        Re: 581368   \n",
       "319                         Re: Meter 6879 - Sept. 00   \n",
       "167  Re: 5 day loss limit violation (4/20 -4/27/2000)   \n",
       "\n",
       "                                            TF_IDF_LDA  \\\n",
       "440  [(0, 0.8427851), (1, 0.017466994), (2, 0.01746...   \n",
       "276  [(0, 0.8427131), (1, 0.017473105), (2, 0.01747...   \n",
       "418  [(0, 0.84261274), (1, 0.017488237), (2, 0.0174...   \n",
       "319  [(0, 0.8343554), (1, 0.01839862), (2, 0.018399...   \n",
       "167  [(0, 0.8143492), (1, 0.020624613), (2, 0.02062...   \n",
       "\n",
       "                          TO_                       _id  \n",
       "440  david.delainey@enron.com  5b4cbc56f63a094ed82995c9  \n",
       "276   peter.weidler@enron.com  5b4cbc54f63a094ed82768c3  \n",
       "418      kate.symes@enron.com  5b4cbc57f63a094ed82cb710  \n",
       "319    daren.farmer@enron.com  5b4cbc54f63a094ed827381a  \n",
       "167    mark.fondren@enron.com  5b4cbc57f63a094ed82bd5ec  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined function to evaluate the STD of Vector's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pos(mean_,limit_pos):\n",
    "    #Index_STD = []\n",
    "    Pos_1 = (list(limit_pos.values())[0])\n",
    "    Pos_2 = (list(limit_pos.values())[1])\n",
    "    Pos_3 = (list(limit_pos.values())[2])\n",
    "    Pos_4 = (list(limit_pos.values())[3])\n",
    "    Pos_5 = (list(limit_pos.values())[4])\n",
    "    Pos_6 = (list(limit_pos.values())[5])\n",
    "    Pos_7 = (list(limit_pos.values())[6])\n",
    "    Pos_8 = (list(limit_pos.values())[7])\n",
    "    Pos_9 = (list(limit_pos.values())[8])\n",
    "    Pos_10 = (list(limit_pos.values())[9])\n",
    " \n",
    "    if Pos_1 <= mean_ <= Pos_2:\n",
    "        Index_STD =(list(limit_pos.keys())[0])   \n",
    "    elif Pos_2 <= mean_ <= Pos_3:\n",
    "        Index_STD = (list(limit_pos.keys())[1])\n",
    "    elif Pos_3 <= mean_ <= Pos_4:\n",
    "        Index_STD =(list(limit_pos.keys())[2])\n",
    "    elif Pos_4 <= mean_ <= Pos_5:\n",
    "        Index_STD =(list(limit_pos.keys())[3])\n",
    "    elif Pos_5 <= mean_ <= Pos_6:\n",
    "        Index_STD =(list(limit_pos.keys())[4])\n",
    "    elif Pos_6 <= mean_ <= Pos_7:\n",
    "        Index_STD =(list(limit_pos.keys())[5])\n",
    "    elif Pos_7 <= mean_ <= Pos_8:\n",
    "        Index_STD =(list(limit_pos.keys())[6])\n",
    "    elif Pos_8 <= mean_ <= Pos_9:\n",
    "        Index_STD =(list(limit_pos.keys())[7])\n",
    "    elif Pos_9 <= mean_ <= Pos_10:\n",
    "        Index_STD =(list(limit_pos.keys())[8])\n",
    "    else:\n",
    "        Index_STD =(2.50)        \n",
    "    return Index_STD\n",
    "\n",
    "def return_neg(mean_,limit_pos):\n",
    "    #Index_STD = []\n",
    "    Pos_1 = (list(limit_pos.values())[0])\n",
    "    Pos_2 = (list(limit_pos.values())[1])\n",
    "    Pos_3 = (list(limit_pos.values())[2])\n",
    "    Pos_4 = (list(limit_pos.values())[3])\n",
    "    Pos_5 = (list(limit_pos.values())[4])\n",
    "    Pos_6 = (list(limit_pos.values())[5])\n",
    "    Pos_7 = (list(limit_pos.values())[6])\n",
    "    Pos_8 = (list(limit_pos.values())[7])\n",
    "    Pos_9 = (list(limit_pos.values())[8])\n",
    "    Pos_10 = (list(limit_pos.values())[9])\n",
    "    if Pos_1 >= mean_ >= Pos_2:\n",
    "        Index_STD =(list(limit_pos.keys())[0])\n",
    "    elif Pos_2 >= mean_ >= Pos_3:\n",
    "        Index_STD = (list(limit_pos.keys())[1])\n",
    "    elif Pos_3 >= mean_ >= Pos_4:\n",
    "        Index_STD =(list(limit_pos.keys())[2])\n",
    "    elif Pos_4 >= mean_ >= Pos_5:\n",
    "        Index_STD =(list(limit_pos.keys())[3])\n",
    "    elif Pos_5 >= mean_ >= Pos_6:\n",
    "        Index_STD =(list(limit_pos.keys())[4])\n",
    "    elif Pos_6 >= mean_ >= Pos_7:\n",
    "        Index_STD =(list(limit_pos.keys())[5])\n",
    "    elif Pos_7 >= mean_ >= Pos_8:\n",
    "        Index_STD =(list(limit_pos.keys())[6])\n",
    "    elif Pos_8 >= mean_ >= Pos_9:\n",
    "        Index_STD =(list(limit_pos.keys())[7])\n",
    "    elif Pos_9 >= mean_ >= Pos_10:\n",
    "        Index_STD =(list(limit_pos.keys())[8])\n",
    "    else:\n",
    "        Index_STD =(2.50)\n",
    "    return Index_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping the STD and Updating the Database with Pandas Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def STD_Sampling_Data_JD_Sep_5(Df,dbname):\n",
    "    MAD = Df.Cos_Simlarity.std(ddof=0)\n",
    "    Place_Value = np.where(Df.Cos_Simlarity == float(100.0000))\n",
    "    print (Place_Value)\n",
    "    Best_Dist   = Df.Cos_Simlarity.iloc[Place_Value[0]]\n",
    "    if len(Best_Dist)==1:\n",
    "        Best_Dist = float(Best_Dist)\n",
    "    else:\n",
    "        Best_Dist = 0\n",
    "    print (\"Best Distance\",Best_Dist)\n",
    "    \n",
    "    Threhold_List = [0,0.25,0.50,0.75,1.0,1.25,1.50,1.75,2.0,2.25]\n",
    "    Positive_Limit = [round(Best_Dist + (thresh * MAD),6) for thresh in Threhold_List]\n",
    "    \n",
    "    Dict_Positive_limit = dict(zip(Threhold_List, Positive_Limit))\n",
    "    \n",
    "    Negative_Limit = [round(Best_Dist - (thresh * MAD),6) for thresh in Threhold_List]\n",
    "    \n",
    "    Dict_Negative_Limit = dict(zip(Threhold_List, Negative_Limit))\n",
    "    \n",
    "    Df[\"Pos\"] =Df.Cos_Simlarity.apply(lambda x: return_pos(x,Dict_Positive_limit))\n",
    "    Df[\"Neg\"] =Df.Cos_Simlarity.apply(lambda x: return_neg(x,Dict_Negative_Limit))\n",
    "    \n",
    "    \n",
    "    \n",
    "    List_Get = [x if x <=y  and x <= 2.50 else y for x,y in zip(Df[\"Pos\"],Df[\"Neg\"])]\n",
    "    Df[\"Pos\"]\n",
    "    Df[\"Neg\"]\n",
    "    Df[\"Response\"] = List_Get\n",
    "#    Df.MATRIX = Df[\"MATRIX\"].astype(str)\n",
    "    Df.SIM_Matirx = Df[\"SIM_Matirx\"].astype(str)\n",
    "    Df.TF_IDF_LDA = Df[\"TF_IDF_LDA\"].astype(str)\n",
    "    #Df.Max_Prob = Df[\"Max_Prob\"].astype(str)\n",
    "    #Df.Cos_Simlarity = Df[\"Cos_Simlarity\"].astype(str)\n",
    "    \n",
    "    \n",
    "    print (Df.info())\n",
    "    \n",
    "    dbname = str(dbname)\n",
    "    collection_name = mydb[dbname]\n",
    "    collection_name.insert_many(Df.to_dict('records'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the above functions to perform task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA_Database\n",
      "Cluster Number is Processed :\t 0\n",
      "(array([0, 1, 2], dtype=int64),)\n",
      "Best Distance 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkdadhich\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\jkdadhich\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\jkdadhich\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\jkdadhich\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34 entries, 440 to 491\n",
      "Data columns (total 18 columns):\n",
      "Body_            34 non-null object\n",
      "Corpus           34 non-null object\n",
      "Cos_Simlarity    34 non-null float64\n",
      "Date_            34 non-null object\n",
      "Doc_N            34 non-null object\n",
      "Doc_Number       34 non-null object\n",
      "From_            34 non-null object\n",
      "Max_Prob         34 non-null float64\n",
      "Prob_Label       34 non-null object\n",
      "Rank_Prob        34 non-null float64\n",
      "SIM_Matirx       34 non-null object\n",
      "Subject_         34 non-null object\n",
      "TF_IDF_LDA       34 non-null object\n",
      "TO_              34 non-null object\n",
      "_id              34 non-null object\n",
      "Pos              34 non-null float64\n",
      "Neg              34 non-null float64\n",
      "Response         34 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 5.0+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 1\n",
      "(array([0], dtype=int64),)\n",
      "Best Distance 100.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49 entries, 18 to 116\n",
      "Data columns (total 18 columns):\n",
      "Body_            49 non-null object\n",
      "Corpus           49 non-null object\n",
      "Cos_Simlarity    49 non-null float64\n",
      "Date_            49 non-null object\n",
      "Doc_N            49 non-null object\n",
      "Doc_Number       49 non-null object\n",
      "From_            49 non-null object\n",
      "Max_Prob         49 non-null float64\n",
      "Prob_Label       49 non-null object\n",
      "Rank_Prob        49 non-null float64\n",
      "SIM_Matirx       49 non-null object\n",
      "Subject_         49 non-null object\n",
      "TF_IDF_LDA       49 non-null object\n",
      "TO_              48 non-null object\n",
      "_id              49 non-null object\n",
      "Pos              49 non-null float64\n",
      "Neg              49 non-null float64\n",
      "Response         49 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 7.3+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 2\n",
      "(array([0], dtype=int64),)\n",
      "Best Distance 100.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 62 entries, 493 to 124\n",
      "Data columns (total 18 columns):\n",
      "Body_            62 non-null object\n",
      "Corpus           62 non-null object\n",
      "Cos_Simlarity    62 non-null float64\n",
      "Date_            62 non-null object\n",
      "Doc_N            62 non-null object\n",
      "Doc_Number       62 non-null object\n",
      "From_            62 non-null object\n",
      "Max_Prob         62 non-null float64\n",
      "Prob_Label       62 non-null object\n",
      "Rank_Prob        62 non-null float64\n",
      "SIM_Matirx       62 non-null object\n",
      "Subject_         62 non-null object\n",
      "TF_IDF_LDA       62 non-null object\n",
      "TO_              57 non-null object\n",
      "_id              62 non-null object\n",
      "Pos              62 non-null float64\n",
      "Neg              62 non-null float64\n",
      "Response         62 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 9.2+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 3\n",
      "(array([0], dtype=int64),)\n",
      "Best Distance 100.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32 entries, 344 to 310\n",
      "Data columns (total 18 columns):\n",
      "Body_            32 non-null object\n",
      "Corpus           32 non-null object\n",
      "Cos_Simlarity    32 non-null float64\n",
      "Date_            32 non-null object\n",
      "Doc_N            32 non-null object\n",
      "Doc_Number       32 non-null object\n",
      "From_            32 non-null object\n",
      "Max_Prob         32 non-null float64\n",
      "Prob_Label       32 non-null object\n",
      "Rank_Prob        32 non-null float64\n",
      "SIM_Matirx       32 non-null object\n",
      "Subject_         32 non-null object\n",
      "TF_IDF_LDA       32 non-null object\n",
      "TO_              32 non-null object\n",
      "_id              32 non-null object\n",
      "Pos              32 non-null float64\n",
      "Neg              32 non-null float64\n",
      "Response         32 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 4.8+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 4\n",
      "(array([0], dtype=int64),)\n",
      "Best Distance 100.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 68 to 343\n",
      "Data columns (total 18 columns):\n",
      "Body_            30 non-null object\n",
      "Corpus           30 non-null object\n",
      "Cos_Simlarity    30 non-null float64\n",
      "Date_            30 non-null object\n",
      "Doc_N            30 non-null object\n",
      "Doc_Number       30 non-null object\n",
      "From_            30 non-null object\n",
      "Max_Prob         30 non-null float64\n",
      "Prob_Label       30 non-null object\n",
      "Rank_Prob        30 non-null float64\n",
      "SIM_Matirx       30 non-null object\n",
      "Subject_         30 non-null object\n",
      "TF_IDF_LDA       30 non-null object\n",
      "TO_              28 non-null object\n",
      "_id              30 non-null object\n",
      "Pos              30 non-null float64\n",
      "Neg              30 non-null float64\n",
      "Response         30 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 4.5+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 5\n",
      "(array([0], dtype=int64),)\n",
      "Best Distance 100.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52 entries, 379 to 154\n",
      "Data columns (total 18 columns):\n",
      "Body_            52 non-null object\n",
      "Corpus           52 non-null object\n",
      "Cos_Simlarity    52 non-null float64\n",
      "Date_            52 non-null object\n",
      "Doc_N            52 non-null object\n",
      "Doc_Number       52 non-null object\n",
      "From_            52 non-null object\n",
      "Max_Prob         52 non-null float64\n",
      "Prob_Label       52 non-null object\n",
      "Rank_Prob        52 non-null float64\n",
      "SIM_Matirx       52 non-null object\n",
      "Subject_         52 non-null object\n",
      "TF_IDF_LDA       52 non-null object\n",
      "TO_              50 non-null object\n",
      "_id              52 non-null object\n",
      "Pos              52 non-null float64\n",
      "Neg              52 non-null float64\n",
      "Response         52 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 7.7+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 6\n",
      "(array([0], dtype=int64),)\n",
      "Best Distance 100.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27 entries, 186 to 316\n",
      "Data columns (total 18 columns):\n",
      "Body_            27 non-null object\n",
      "Corpus           27 non-null object\n",
      "Cos_Simlarity    27 non-null float64\n",
      "Date_            27 non-null object\n",
      "Doc_N            27 non-null object\n",
      "Doc_Number       27 non-null object\n",
      "From_            27 non-null object\n",
      "Max_Prob         27 non-null float64\n",
      "Prob_Label       27 non-null object\n",
      "Rank_Prob        27 non-null float64\n",
      "SIM_Matirx       27 non-null object\n",
      "Subject_         27 non-null object\n",
      "TF_IDF_LDA       27 non-null object\n",
      "TO_              27 non-null object\n",
      "_id              27 non-null object\n",
      "Pos              27 non-null float64\n",
      "Neg              27 non-null float64\n",
      "Response         27 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 4.0+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 7\n",
      "(array([0, 1], dtype=int64),)\n",
      "Best Distance 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48 entries, 30 to 14\n",
      "Data columns (total 18 columns):\n",
      "Body_            48 non-null object\n",
      "Corpus           48 non-null object\n",
      "Cos_Simlarity    48 non-null float64\n",
      "Date_            48 non-null object\n",
      "Doc_N            48 non-null object\n",
      "Doc_Number       48 non-null object\n",
      "From_            48 non-null object\n",
      "Max_Prob         48 non-null float64\n",
      "Prob_Label       48 non-null object\n",
      "Rank_Prob        48 non-null float64\n",
      "SIM_Matirx       48 non-null object\n",
      "Subject_         48 non-null object\n",
      "TF_IDF_LDA       48 non-null object\n",
      "TO_              47 non-null object\n",
      "_id              48 non-null object\n",
      "Pos              48 non-null float64\n",
      "Neg              48 non-null float64\n",
      "Response         48 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 7.1+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 8\n",
      "(array([0], dtype=int64),)\n",
      "Best Distance 100.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 120 entries, 118 to 426\n",
      "Data columns (total 18 columns):\n",
      "Body_            120 non-null object\n",
      "Corpus           120 non-null object\n",
      "Cos_Simlarity    120 non-null float64\n",
      "Date_            120 non-null object\n",
      "Doc_N            120 non-null object\n",
      "Doc_Number       120 non-null object\n",
      "From_            120 non-null object\n",
      "Max_Prob         120 non-null float64\n",
      "Prob_Label       120 non-null object\n",
      "Rank_Prob        120 non-null float64\n",
      "SIM_Matirx       120 non-null object\n",
      "Subject_         120 non-null object\n",
      "TF_IDF_LDA       120 non-null object\n",
      "TO_              118 non-null object\n",
      "_id              120 non-null object\n",
      "Pos              120 non-null float64\n",
      "Neg              120 non-null float64\n",
      "Response         120 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 17.8+ KB\n",
      "None\n",
      "Cluster Number is Processed :\t 9\n",
      "(array([0, 1], dtype=int64),)\n",
      "Best Distance 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46 entries, 364 to 318\n",
      "Data columns (total 18 columns):\n",
      "Body_            46 non-null object\n",
      "Corpus           46 non-null object\n",
      "Cos_Simlarity    46 non-null float64\n",
      "Date_            46 non-null object\n",
      "Doc_N            46 non-null object\n",
      "Doc_Number       46 non-null object\n",
      "From_            46 non-null object\n",
      "Max_Prob         46 non-null float64\n",
      "Prob_Label       46 non-null object\n",
      "Rank_Prob        46 non-null float64\n",
      "SIM_Matirx       46 non-null object\n",
      "Subject_         46 non-null object\n",
      "TF_IDF_LDA       46 non-null object\n",
      "TO_              43 non-null object\n",
      "_id              46 non-null object\n",
      "Pos              46 non-null float64\n",
      "Neg              46 non-null float64\n",
      "Response         46 non-null float64\n",
      "dtypes: float64(6), object(12)\n",
      "memory usage: 6.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient # MongoDB\n",
    "client = MongoClient() # class of mongoDb\n",
    "client = MongoClient('localhost', 27017) # connection port\n",
    "mydb = client['New_Data_Email']\n",
    "dbname = \"LDA_Database\"\n",
    "\n",
    "def Clean_DB_First_JD(dbname):\n",
    "    mydb = client['New_Data_Email']\n",
    "    #print (mydb.collection_names())\n",
    "    \n",
    "    collection_name = mydb[dbname]\n",
    "    print (collection_name.name)\n",
    "    \n",
    "    #print (collection_name.count())\n",
    "    collection_name.remove()\n",
    "    \n",
    "Clean_DB_First_JD(dbname)\n",
    "\n",
    "for j in range(Number_of_Topics):\n",
    "    print (\"Cluster Number is Processed :\\t\",j)\n",
    "    Demo = blank_df.loc[blank_df.Prob_Label == j]\n",
    "    STD_Sampling_Data_JD_Sep_5(Demo,dbname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_email_Result = pd.DataFrame(list(mydb.LDA_Database.find()))\n",
    "len(Data_email_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Body_', 'Corpus', 'Cos_Simlarity', 'Date_', 'Doc_N', 'Doc_Number',\n",
       "       'From_', 'Max_Prob', 'Neg', 'Pos', 'Prob_Label', 'Rank_Prob',\n",
       "       'Response', 'SIM_Matirx', 'Subject_', 'TF_IDF_LDA', 'TO_', '_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_email_Result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body_</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Cos_Simlarity</th>\n",
       "      <th>Date_</th>\n",
       "      <th>Doc_N</th>\n",
       "      <th>Doc_Number</th>\n",
       "      <th>From_</th>\n",
       "      <th>Max_Prob</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Prob_Label</th>\n",
       "      <th>Rank_Prob</th>\n",
       "      <th>Response</th>\n",
       "      <th>SIM_Matirx</th>\n",
       "      <th>Subject_</th>\n",
       "      <th>TF_IDF_LDA</th>\n",
       "      <th>TO_</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dave,\\n\\nwe had a meeting today with mark frev...</td>\n",
       "      <td>[[12, 1], [53, 1], [64, 2], [208, 1], [219, 1]...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Mon, 17 Jul 2000 11:25:00 -0700 (PDT)</td>\n",
       "      <td>263373</td>\n",
       "      <td>441</td>\n",
       "      <td>kimberly.hillis@enron.com</td>\n",
       "      <td>84.2785</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>(0.0723559, 0.04214374, 0.057439364, 0.0560173...</td>\n",
       "      <td>Alberta PPA</td>\n",
       "      <td>[(0, 0.8427851), (1, 0.017466994), (2, 0.01746...</td>\n",
       "      <td>david.delainey@enron.com</td>\n",
       "      <td>5b4cbc56f63a094ed82995c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i will be out on th &amp; fri because my wife is h...</td>\n",
       "      <td>[[42, 1], [113, 1], [162, 1], [169, 1], [177, ...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Wed, 24 Jan 2001 08:32:00 -0800 (PST)</td>\n",
       "      <td>120775</td>\n",
       "      <td>277</td>\n",
       "      <td>rob.gay@enron.com</td>\n",
       "      <td>84.2707</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>(0.07236882, 0.04215669, 0.05746351, 0.0560301...</td>\n",
       "      <td>Wife's surgery and Bersani</td>\n",
       "      <td>[(0, 0.8427131), (1, 0.017473105), (2, 0.01747...</td>\n",
       "      <td>peter.weidler@enron.com</td>\n",
       "      <td>5b4cbc54f63a094ed82768c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can you kill this deal or zero out the volumes...</td>\n",
       "      <td>[[38, 3], [84, 1], [156, 2], [192, 1], [287, 2...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Wed, 25 Apr 2001 08:13:00 -0700 (PDT)</td>\n",
       "      <td>468500</td>\n",
       "      <td>419</td>\n",
       "      <td>rhonda.denton@enron.com</td>\n",
       "      <td>84.2613</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>(0.07239429, 0.0421756, 0.05748879, 0.05604868...</td>\n",
       "      <td>Re: 581368</td>\n",
       "      <td>[(0, 0.84261274), (1, 0.017488237), (2, 0.0174...</td>\n",
       "      <td>kate.symes@enron.com</td>\n",
       "      <td>5b4cbc57f63a094ed82cb710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this deal was not put in right.  the primary t...</td>\n",
       "      <td>[[0, 1], [38, 1], [76, 1], [79, 1], [82, 1], [...</td>\n",
       "      <td>99.9975</td>\n",
       "      <td>Wed, 13 Sep 2000 06:37:00 -0700 (PDT)</td>\n",
       "      <td>108318</td>\n",
       "      <td>320</td>\n",
       "      <td>julie.meyers@enron.com</td>\n",
       "      <td>83.4331</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>(0.074123114, 0.043649085, 0.0595716, 0.057638...</td>\n",
       "      <td>Re: Meter 6879 - Sept. 00</td>\n",
       "      <td>[(0, 0.8343554), (1, 0.01839862), (2, 0.018399...</td>\n",
       "      <td>daren.farmer@enron.com</td>\n",
       "      <td>5b4cbc54f63a094ed827381a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>again mark i am flattered that you include me ...</td>\n",
       "      <td>[[160, 1], [169, 1], [256, 2], [288, 3], [641,...</td>\n",
       "      <td>99.9713</td>\n",
       "      <td>Fri, 28 Apr 2000 03:45:00 -0700 (PDT)</td>\n",
       "      <td>410864</td>\n",
       "      <td>168</td>\n",
       "      <td>susan.scott@enron.com</td>\n",
       "      <td>81.4350</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>(0.07847097, 0.047362793, 0.06464015, 0.061656...</td>\n",
       "      <td>Re: 5 day loss limit violation (4/20 -4/27/2000)</td>\n",
       "      <td>[(0, 0.8143492), (1, 0.020624613), (2, 0.02062...</td>\n",
       "      <td>mark.fondren@enron.com</td>\n",
       "      <td>5b4cbc57f63a094ed82bd5ec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Body_  \\\n",
       "0  dave,\\n\\nwe had a meeting today with mark frev...   \n",
       "1  i will be out on th & fri because my wife is h...   \n",
       "2  can you kill this deal or zero out the volumes...   \n",
       "3  this deal was not put in right.  the primary t...   \n",
       "4  again mark i am flattered that you include me ...   \n",
       "\n",
       "                                              Corpus  Cos_Simlarity  \\\n",
       "0  [[12, 1], [53, 1], [64, 2], [208, 1], [219, 1]...       100.0000   \n",
       "1  [[42, 1], [113, 1], [162, 1], [169, 1], [177, ...       100.0000   \n",
       "2  [[38, 3], [84, 1], [156, 2], [192, 1], [287, 2...       100.0000   \n",
       "3  [[0, 1], [38, 1], [76, 1], [79, 1], [82, 1], [...        99.9975   \n",
       "4  [[160, 1], [169, 1], [256, 2], [288, 3], [641,...        99.9713   \n",
       "\n",
       "                                   Date_   Doc_N  Doc_Number  \\\n",
       "0  Mon, 17 Jul 2000 11:25:00 -0700 (PDT)  263373         441   \n",
       "1  Wed, 24 Jan 2001 08:32:00 -0800 (PST)  120775         277   \n",
       "2  Wed, 25 Apr 2001 08:13:00 -0700 (PDT)  468500         419   \n",
       "3  Wed, 13 Sep 2000 06:37:00 -0700 (PDT)  108318         320   \n",
       "4  Fri, 28 Apr 2000 03:45:00 -0700 (PDT)  410864         168   \n",
       "\n",
       "                       From_  Max_Prob  Neg  Pos  Prob_Label  Rank_Prob  \\\n",
       "0  kimberly.hillis@enron.com   84.2785  2.5  2.5           0        1.0   \n",
       "1          rob.gay@enron.com   84.2707  2.5  2.5           0        2.0   \n",
       "2    rhonda.denton@enron.com   84.2613  2.5  2.5           0        3.0   \n",
       "3     julie.meyers@enron.com   83.4331  2.5  2.5           0        4.0   \n",
       "4      susan.scott@enron.com   81.4350  2.5  2.5           0        5.0   \n",
       "\n",
       "   Response                                         SIM_Matirx  \\\n",
       "0       2.5  (0.0723559, 0.04214374, 0.057439364, 0.0560173...   \n",
       "1       2.5  (0.07236882, 0.04215669, 0.05746351, 0.0560301...   \n",
       "2       2.5  (0.07239429, 0.0421756, 0.05748879, 0.05604868...   \n",
       "3       2.5  (0.074123114, 0.043649085, 0.0595716, 0.057638...   \n",
       "4       2.5  (0.07847097, 0.047362793, 0.06464015, 0.061656...   \n",
       "\n",
       "                                           Subject_  \\\n",
       "0                                       Alberta PPA   \n",
       "1                        Wife's surgery and Bersani   \n",
       "2                                        Re: 581368   \n",
       "3                         Re: Meter 6879 - Sept. 00   \n",
       "4  Re: 5 day loss limit violation (4/20 -4/27/2000)   \n",
       "\n",
       "                                          TF_IDF_LDA  \\\n",
       "0  [(0, 0.8427851), (1, 0.017466994), (2, 0.01746...   \n",
       "1  [(0, 0.8427131), (1, 0.017473105), (2, 0.01747...   \n",
       "2  [(0, 0.84261274), (1, 0.017488237), (2, 0.0174...   \n",
       "3  [(0, 0.8343554), (1, 0.01839862), (2, 0.018399...   \n",
       "4  [(0, 0.8143492), (1, 0.020624613), (2, 0.02062...   \n",
       "\n",
       "                        TO_                       _id  \n",
       "0  david.delainey@enron.com  5b4cbc56f63a094ed82995c9  \n",
       "1   peter.weidler@enron.com  5b4cbc54f63a094ed82768c3  \n",
       "2      kate.symes@enron.com  5b4cbc57f63a094ed82cb710  \n",
       "3    daren.farmer@enron.com  5b4cbc54f63a094ed827381a  \n",
       "4    mark.fondren@enron.com  5b4cbc57f63a094ed82bd5ec  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_email_Result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_email_Result.to_excel(\"Sample_.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
